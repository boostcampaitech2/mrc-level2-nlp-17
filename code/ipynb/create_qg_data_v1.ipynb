{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd157ccb-b61c-41bc-af77-9737692661c9",
   "metadata": {},
   "source": [
    "### QG_data_V1\n",
    "\n",
    "Question generation model 깃 주소\n",
    "https://github.com/codertimo/KorQuAD-Question-Generation\n",
    "\n",
    "Question generation source - 토론게시판 문하겸 캠퍼님\n",
    "https://stages.ai/competitions/77/discussion/talk/post/769\n",
    "\n",
    "\n",
    "깃에서 학습된 QG 모델을 다운로드 해주시고 load_state_dict() 에서 위치를 설정해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80ef463e-8bc0-4827-92c1-30ff4032f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import datasets\n",
    "from time import sleep\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d92d5-f5e8-4bf2-8e4c-6dc5b3389acf",
   "metadata": {},
   "source": [
    "### 학습데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedf9674-324d-482a-83ad-d05609cae09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>corpus_source</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>html</th>\n",
       "      <th>document_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개...</td>\n",
       "      <td>위키피디아</td>\n",
       "      <td>TODO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>나라 목록</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 하였다. 협정...</td>\n",
       "      <td>위키피디아</td>\n",
       "      <td>TODO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>나라 목록</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>현 서울특별시 종로구 서린동 (구 일제 강점기 경기도 경성부 서린정) 출신이다. 친...</td>\n",
       "      <td>위키피디아</td>\n",
       "      <td>TODO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>백남준</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>아오조라 문고(靑空文庫, あおぞらぶんこ|아오조라 분고)는 ‘일본어판 구텐베르크 프로...</td>\n",
       "      <td>위키피디아</td>\n",
       "      <td>TODO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>아오조라 문고</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>저자 사망 이후 50년이 지나 저작권이 소멸한 메이지 시대부터 쇼와 시대 초기까지의...</td>\n",
       "      <td>위키피디아</td>\n",
       "      <td>TODO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>아오조라 문고</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text corpus_source   url  \\\n",
       "0  이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개...         위키피디아  TODO   \n",
       "1  이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 하였다. 협정...         위키피디아  TODO   \n",
       "2  현 서울특별시 종로구 서린동 (구 일제 강점기 경기도 경성부 서린정) 출신이다. 친...         위키피디아  TODO   \n",
       "3  아오조라 문고(靑空文庫, あおぞらぶんこ|아오조라 분고)는 ‘일본어판 구텐베르크 프로...         위키피디아  TODO   \n",
       "4  저자 사망 이후 50년이 지나 저작권이 소멸한 메이지 시대부터 쇼와 시대 초기까지의...         위키피디아  TODO   \n",
       "\n",
       "   domain    title  author  html  document_id  \n",
       "0     NaN    나라 목록     NaN   NaN            0  \n",
       "1     NaN    나라 목록     NaN   NaN            1  \n",
       "2     NaN      백남준     NaN   NaN            2  \n",
       "3     NaN  아오조라 문고     NaN   NaN            3  \n",
       "4     NaN  아오조라 문고     NaN   NaN            4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.read_json(\"../../data/wikipedia_documents.json\", orient='index')\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3270bcb-ccb7-4eee-bc03-b7f4592c7d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개...</td>\n",
       "      <td>나라 목록</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>현 서울특별시 종로구 서린동 (구 일제 강점기 경기도 경성부 서린정) 출신이다. 친...</td>\n",
       "      <td>백남준</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아오조라 문고(靑空文庫, あおぞらぶんこ|아오조라 분고)는 ‘일본어판 구텐베르크 프로...</td>\n",
       "      <td>아오조라 문고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>아오조라 문고는 자원봉사로 운영되며 열람 역시 무료이다.  서비스 개시 초반에는 보...</td>\n",
       "      <td>아오조라 문고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>텍스트 파일을 아오조라 문고에 수록할 때, 텍스트 파일이 갖추어야 할 서식을 '아오...</td>\n",
       "      <td>아오조라 문고</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    title\n",
       "0  이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개...    나라 목록\n",
       "1  현 서울특별시 종로구 서린동 (구 일제 강점기 경기도 경성부 서린정) 출신이다. 친...      백남준\n",
       "2  아오조라 문고(靑空文庫, あおぞらぶんこ|아오조라 분고)는 ‘일본어판 구텐베르크 프로...  아오조라 문고\n",
       "3  아오조라 문고는 자원봉사로 운영되며 열람 역시 무료이다.  서비스 개시 초반에는 보...  아오조라 문고\n",
       "4  텍스트 파일을 아오조라 문고에 수록할 때, 텍스트 파일이 갖추어야 할 서식을 '아오...  아오조라 문고"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "titles = []\n",
    "\n",
    "for i in range(len(wiki_df)):\n",
    "    wiki_context = wiki_df['text'][i]\n",
    "    wiki_title = wiki_df['title'][i]\n",
    "\n",
    "    if wiki_title in wiki_context:\n",
    "        texts.append(wiki_context)\n",
    "        titles.append(wiki_title)\n",
    "\n",
    "wiki_qa_df = pd.DataFrame(data={'text':texts,'title':titles})\n",
    "wiki_qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15b4d30c-205e-4a33-827f-085889cd22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_qa_df.to_csv('/opt/ml/data/wiki_text_title.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c0a1f6-8a8a-46ec-b695-347693b9272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KorQuAD-Question-Generation'...\n",
      "remote: Enumerating objects: 125, done.\u001b[K\n",
      "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 125 (delta 54), reused 105 (delta 39), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (125/125), 926.44 KiB | 2.59 MiB/s, done.\n",
      "Resolving deltas: 100% (54/54), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/codertimo/KorQuAD-Question-Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f782176b-189b-40da-a772-a190512dc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"KorQuAD-Question-Generation\")\n",
    "from korquad_qg.dataset import QAExample\n",
    "\n",
    "def load_wiki_dataset(dataset_path):\n",
    "    wiki_data_frame = pd.read_csv(dataset_path)\n",
    "    examples = []\n",
    "    for idx in range(len(wiki_data_frame)):\n",
    "        text = wiki_data_frame[\"text\"][idx]\n",
    "        title = wiki_data_frame[\"title\"][idx]\n",
    "\n",
    "        example = QAExample(text, title)\n",
    "        examples.append(example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235996f-0ae7-462e-a2d5-07e271b3b3c9",
   "metadata": {},
   "source": [
    "### 질문 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94618a3d-a14b-4e5a-9952-afcdf3f04e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "sys.path.append(\"KorQuAD-Question-Generation\")\n",
    "from korquad_qg.config import QGConfig\n",
    "from korquad_qg.dataset import (MAX_QUESTION_SPACE, MIN_QUESTION_SPACE, QGDecodingDataset)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"taeminlee/kogpt2\")\n",
    "\n",
    "# 여기서 다운로드한 모델 경로 설정해주세요\n",
    "model.load_state_dict(torch.load('./KorQuAD-Question-Generation/QG_kogpt2.pth', map_location=\"cpu\"))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer.from_file(\n",
    "    vocab_filename=\"./KorQuAD-Question-Generation/tokenizer/vocab.json\", merges_filename=\"./KorQuAD-Question-Generation/tokenizer/merges.txt\", add_prefix_space=False\n",
    ")\n",
    "\n",
    "examples = load_wiki_dataset('/opt/ml/data/wiki_text_title.csv')\n",
    "random.shuffle(examples)\n",
    "dataset = QGDecodingDataset(examples, tokenizer, 512)\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "generated_results = []\n",
    "\n",
    "for i, batch in tqdm(enumerate(dataloader), desc=\"generate\", total=len(dataloader)):\n",
    "    input_ids, attention_mask = (v.to(device) for v in batch)\n",
    "    origin_seq_len = input_ids.size(-1)\n",
    "\n",
    "    decoded_sequences = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=origin_seq_len + MAX_QUESTION_SPACE,\n",
    "        min_length=origin_seq_len + MIN_QUESTION_SPACE,\n",
    "        pad_token_id=0,\n",
    "        bos_token_id=1,\n",
    "        eos_token_id=2,\n",
    "        num_beams=5,\n",
    "        repetition_penalty=1.3,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "    for decoded_tokens in decoded_sequences.tolist():\n",
    "        decoded_question_text = tokenizer.decode(decoded_tokens[origin_seq_len:])\n",
    "        decoded_question_text = decoded_question_text.split(\"</s>\")[0].replace(\"<s>\", \"\")\n",
    "        generated_results.append(\n",
    "            (examples[i].context, examples[i].answer, examples[i].question, decoded_question_text)\n",
    "        )\n",
    "\n",
    "# with open('test.tsv', \"w\") as f:\n",
    "#     for context, answer, question, generated_question in generated_results:\n",
    "#         f.write(f\"{generated_question}\\t{answer}\\t{context}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aefbd8-7e0d-427c-8e0f-71088f16b60f",
   "metadata": {},
   "source": [
    "### 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "296e1d57-f5e2-45d1-bf4f-9924e30796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "answers = []\n",
    "questions = []\n",
    "\n",
    "for context, answer, question, generated_question in generated_results:\n",
    "    contexts.append(context)\n",
    "    answers.append(answer)\n",
    "    questions.append(generated_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ffcf1-974b-46bd-9c06-51fb68b7fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = []\n",
    "context_dict = {}\n",
    "for i in range(len(wiki_df)):\n",
    "    context_dict[wiki_df['text'][i]] = wiki_df['document_id'][i]\n",
    "\n",
    "for context in tqdm(contexts, position=0):\n",
    "    doc_ids.append(context_dict[context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17e1e9f9-53f5-4e1b-870b-8f08ac1a377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_start_idx = []\n",
    "\n",
    "for c, a in zip(contexts, answers):\n",
    "    answer_start_idx.append(c.find(a))\n",
    "    \n",
    "answers_ = [{'answer_start':[i], 'text':[a]} for i, a in zip(answer_start_idx, answers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1caea-8908-4ab0-bd10-0f0cb81b289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_ids), len(generated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5d91184b-f303-41f6-8a47-b76ba4f27059",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk(\"../../data/train_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "79cd7f8e-cb62-4797-b1f5-4e0360e40096",
   "metadata": {},
   "outputs": [],
   "source": [
    "qg_train_dict = {\n",
    "    '__index_level_0__':[0]*len(doc_ids),\n",
    "    'id':[0]*len(doc_ids),\n",
    "    'question':questions,\n",
    "    'title':answers, \n",
    "    'context':contexts, \n",
    "    'answers':answers_, \n",
    "    \"document_id\":doc_ids,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4ecd6c38-d3ab-4a31-a339-a64da20dd451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = datasets.DatasetDict({\n",
    "    \"train\": datasets.arrow_dataset.Dataset.from_dict(qg_train_dict),\n",
    "    \"validation\": train_dataset['validation'],\n",
    "})\n",
    "\n",
    "dataset_dict.save_to_disk(\"../../data/qg_data_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "98535de4-a5b1-4a1b-af23-a64e1aaba6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "        num_rows: 28765\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['__index_level_0__', 'answers', 'context', 'document_id', 'id', 'question', 'title'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = load_from_disk('../../data/qg_data_v1')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b33226b4-11cb-4f32-82b6-a8a896707eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__index_level_0__': 0,\n",
      " 'answers': {'answer_start': [307], 'text': ['대전역 가락국수']},\n",
      " 'context': '경부선과 호남선의 옛 분기 구조에서 기인하는데, 일제 강점기에 조선총독부에서 호남지역 곡물을 부산으로 이동시켜 수탈해 '\n",
      "            '가기 쉽게 하기 위하여 호남선의 선구가 경부선의 대전역에서 부산 방향을 향하도록 호남선을 부설하였다.\\\\n\\\\n그러다 '\n",
      "            '보니 서울에서 호남선을 이용하여 호남 지방으로 가려면 현재와는 달리 대전역까지 갔다가 대전역에서 기관차의 방향을 '\n",
      "            '반대로 바꿔서 가는 것이 불가피하였고, 이 작업이 오랜 시간을 소요하기 때문에 그 시간을 노려서 대전역에서 잠시 내린 '\n",
      "            '후 승강장의 식당으로 가서 가락국수를 시켜먹는 사람들이 많이 있었다.\\\\n\\\\n이 때문에 대전역 가락국수는 자연히 '\n",
      "            '대전역의 명물이 되었다. 그 후 호남선이 대전역을 경유하지 않고 대전조차장에서 서대전역으로 분기하는 구조로 바뀐 '\n",
      "            '현재까지도, 승강장에서 도착 열차 대기 중 대전역 가락국수를 찾는 사람들이 있고, 환승열차 30분 대기 중에 '\n",
      "            '가락국수를 찾는 고객들도 이를 많이 이용하고 있다.\\\\n\\\\n가락국수는 대전역뿐만 아니라 경부선에서 장항선이 분기하는 '\n",
      "            '천안역, 중앙선에서 태백선과 충북선이 분기하는 제천역, 경부선에서 대구선이 분기하는 대구역이나 동대구역 등에서도 '\n",
      "            '팔았다.',\n",
      " 'document_id': 20216,\n",
      " 'id': 0,\n",
      " 'question': '충청선에서 대전까지 운행한 가락국수의 이름은?',\n",
      " 'title': '대전역 가락국수'}\n"
     ]
    }
   ],
   "source": [
    "pprint(test_dataset['train'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bb5f51fb-dd5f-4af2-8366-8d639bafc5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__index_level_0__': 2146,\n",
      " 'answers': {'answer_start': [284], 'text': ['한보철강']},\n",
      " 'context': '순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법시험에 합격하여 판사로 임용되었고 '\n",
      "            '대법원 재판연구관, 수원지법 부장판사, 사법연수원 교수, 특허법원 부장판사 등을 거쳐 능력을 인정받았다. 2003년 '\n",
      "            '최종영 대법원장의 지명으로 헌법재판소 재판관을 역임하였다.\\\\n\\\\n경제민주화위원회(위원장 장하성이 소액주주들을 '\n",
      "            '대표해 한보철강 부실대출에 책임이 있는 이철수 전 제일은행장 등 임원 4명을 상대로 제기한 손해배상청구소송에서 '\n",
      "            '서울지방법원 민사합의17부는 1998년 7월 24일에 \"한보철강에 부실 대출하여 은행에 막대한 손해를 끼친 점이 '\n",
      "            '인정된다\"며 \"원고가 배상을 청구한 400억원 전액을 은행에 배상하라\"고 하면서 부실 경영인에 대한 최초의 배상 '\n",
      "            '판결을 했다. \\\\n\\\\n2004년 10월 신행정수도의건설을위한특별조치법 위헌 확인 소송에서 9인의 재판관 중 '\n",
      "            '유일하게 각하 견해를 내었다. 소수의견에서 전효숙 재판관은 다수견해의 문제점을 지적하면서 관습헌법 법리를 부정하였다. '\n",
      "            '전효숙 재판관은 서울대학교 근대법학교육 백주년 기념관에서 열린 강연에서, 국회가 고도의 정치적인 사안을 정치로 '\n",
      "            '풀기보다는 헌법재판소에 무조건 맡겨서 해결하려는 자세는 헌법재판소에게 부담스럽다며 소회를 밝힌 바 있다.',\n",
      " 'document_id': 9027,\n",
      " 'id': 'mrc-0-003264',\n",
      " 'question': '처음으로 부실 경영인에 대한 보상 선고를 받은 회사는?',\n",
      " 'title': '전효숙'}\n"
     ]
    }
   ],
   "source": [
    "pprint(test_dataset['validation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a302f9a2-6989-4361-b25c-d7716c10bb41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
